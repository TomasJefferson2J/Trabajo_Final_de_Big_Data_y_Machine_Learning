# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rW8FLeJyO10TvEuZj68TyRWsxkAlwXup
"""

# Importamos las bibliotecas necesarias
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
# Preparamos los datos de entrenamiento
# Datos de entrada (valores RGB)
X = np.array([[255, 0, 0],    # Rojo
              [0, 255, 0],    # Verde
              [0, 0, 255],    # Azul
              [255, 255, 0],  # Amarillo
              [255, 0, 255]]) # Magenta

# Etiquetas o n√∫meros correspondientes a los colores
y = np.array([0, 1, 2, 3, 4])  # 0: Rojo, 1: Verde, 2: Azul, 3: Amarillo, 4: Magenta
# Normalizar los datos
# Normalizar los datos
X = X / 255.0
# Codificar las etiquetas (one-hot encoding)
num_classes = len(np.unique(y))
y_encoded = np.eye(num_classes)[y]
# Definimos y compilamos el modelo de la red neuronal
# Definir el modelo de la red neuronal
model = Sequential()
model.add(Dense(4, input_dim=3, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

# Compilar el modelo
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
#Entrenamos el modelo

model.fit(X, y_encoded, epochs=100, batch_size=1)
# Datos de prueba para hacer predicciones
X_test = np.array([[128, 128, 0],   # Color amarillo-verdoso
                   [0, 128, 128]])  # Color cian

# Normalizar los datos de prueba
X_test = X_test / 255.0
# Codificamos las etiquetas
# Realizar predicciones
predictions = model.predict(X_test)
predicted_labels = np.argmax(predictions, axis=1)

# Decodificar las etiquetas predichas
color_labels = ['Rojo', 'Verde', 'Azul', 'Amarillo', 'Magenta']
predicted_colors = [color_labels[label] for label in predicted_labels]

print(predicted_colors)